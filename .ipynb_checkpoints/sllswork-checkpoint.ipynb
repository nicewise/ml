{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a370b11",
   "metadata": {},
   "source": [
    "# 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a297af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seri(x, s):\n",
    "    h,w = x.shape\n",
    "    o = np.zeros((h-s+1)*s*w).reshape(h-s+1, s, w)\n",
    "    for i in range(h-s+1):\n",
    "        o[i] = x[i:i+s]\n",
    "    return(o)\n",
    "def xy(data_t, s):\n",
    "    data_y = data[sql:, :3]\n",
    "    data_x = np.concatenate((data[:-1, :3], data[1:, 3:]), axis=1)\n",
    "    data_x = seri(data_x, s)\n",
    "    return(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04909808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    _, l = x.shape\n",
    "    x_min = []\n",
    "    x_space = []\n",
    "    for i in range(l):\n",
    "        x_min_i = x[:, i].min()\n",
    "        x_min.append(x_min_i)\n",
    "        x_space.append(x[:, i].max() - x_min_i)\n",
    "        x[:, i] = (x[:, i] - x_min_i) / x_space[i]\n",
    "    return(x, x_min, x_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data4.csv\")\n",
    "data = np.array(data, dtype = np.float32)\n",
    "print(data.shape)\n",
    "data, x_min, x_space = normalization(data)\n",
    "sql = 50 # 序列长度\n",
    "data0 = data[0:2604]\n",
    "data5 = data[2604:6025]\n",
    "data10 = data[6025:10019]\n",
    "data15 = data[10019:14678]\n",
    "data25 = data[14678:20032]\n",
    "data30 = data[20032:25739]\n",
    "\n",
    "(x0, y0) = xy(data0, sql)\n",
    "(x5, y5) = xy(data5, sql)\n",
    "(x10, y10) = xy(data10, sql)\n",
    "(x15, y15) = xy(data15, sql)\n",
    "(x25, y25) = xy(data25, sql)\n",
    "(x30, y30) = xy(data30, sql)\n",
    "train_x = np.concatenate((x0, x5, x10, x15, x25, x30), axis=0)\n",
    "train_y = np.concatenate((y0, y5, y10, y15, y25, y30), axis=0)\n",
    "data20 = data[25739:30874]\n",
    "(test_x, test_y) = xy(data20, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = myDataset(train_x, train_y)\n",
    "test_dataset = myDataset(test_x, test_y)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size)\n",
    "# for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "#     print('Step: ', step, '| batch x: ', batch_x.shape, '| batch y: ', batch_y.shape)\n",
    "#     model(batch_x.float())\n",
    "#     print(batch_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3c0ef",
   "metadata": {},
   "source": [
    "# 网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class cons(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "        super(cons, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layer, dropout=0.2, batch_first=True)\n",
    "        # 上面这个dropout=0.2, 不会在最后一层之后加dropout层\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.dense = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        l_out, (hn, cn) = self.lstm(x)\n",
    "        o = hn.squeeze(0)\n",
    "#         o = self.dropout(o)\n",
    "        o = self.dense(o)\n",
    "        o = F.relu(o)\n",
    "        return o\n",
    "\n",
    "input_size, hidden_size, num_layer, output_size = 5, 120, 1, 3\n",
    "model = cons(input_size, hidden_size, num_layer, output_size) # 实例化模型\n",
    "model.float()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2009e",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68002734",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# from datetime import datetime\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        inputs, actual = data\n",
    "        outputs = model(inputs.float())\n",
    "        loss = loss_fn(outputs, actual)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 200 == 0:\n",
    "            last_loss = running_loss / 200 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631dafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    model.train(False)\n",
    "#     model.eval()\n",
    "    running_tloss = 0.0\n",
    "    for i, tdata in enumerate(test_loader):\n",
    "        tinputs, tactual = tdata\n",
    "        toutputs = model(tinputs.float())\n",
    "        tloss = loss_fn(toutputs, tactual)\n",
    "        running_tloss += tloss.item()\n",
    "\n",
    "    avg_tloss = running_tloss / (i + 1)\n",
    "    print('LOSS: train {} test {}'.format(avg_loss, avg_tloss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
